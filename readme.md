# Concept Generator

## General Information

Concept Generator utilizes ChatGPT 3.5 to generate multifaceted data 
about concepts, which are fundamental building blocks in thinking. 
The project yields three types of data:

- Relational (i.e., how concepts relate to one another)
- Comparative (i.e., how concepts rate along specific continua)
- Descriptive (i.e., what do different concepts mean?)

The outcome of the project is a Google Firestore database that provides
easy and efficient access to the generated data. In fact, 
[ConceptExplorer](https://github.com/JoelHKV/ConceptExplorer) is a web 
app that utilizes the data generated in this project in a user-friendly manner.

## Introduction

Concepts are the foundation of human thinking and understanding. 
They allow us to make sense of the world by organizing information 
into meaningful categories. While we grasp many concepts, 
our understanding of them is often intuitive rather than explicit. 
For example, explaining what 'the mind' truly is can be challenging.

The Concept Generator project takes a systematic approach to the 
world of concepts by harnessing the power of ChatGPT 3.5. 
With Concept Generator, you can:

- Initiate the creation of an interrelated concept network from a user-defined starting concept
- Evaluate concepts across any dimension, providing valuable insights into the spectrum of thought
- Generate clear and concise summaries for each concept, making complex ideas more accessible
 
The project produces data that can be useful for:

- Learning new concepts
- Enhancing the understanding of concepts already known
- Acquiring knowledge about the interconnections between concepts
- Categorizing and rating concepts across various dimensions

In essence, the data generated by this project can improve one's conceptual thinking skills, better equipping individuals to interact with the world around them.

The project is designed for learners, educators, researchers, and anyone curious about the intricacies of human thought.

Additionally, explore [ConceptExplorer](https://github.com/JoelHKV/ConceptExplorer), the application-side sister project that complements this endeavor.
 
## Getting Started
To run this project locally, follow these 5 steps:

1. **Installation:**
Ensure you have Python 3.9.5 or a more recent version installed on your system.

2. **Clone the Repository:**
```
git clone https://github.com/JoelHKV/ConceptGenerator.git
```
3. **Install Dependencies:**
Navigate to the project directory and install dependencies:
```
pip install -r requirements.txt
```
4. **Configuration:**
Set up API keys. Refer Section [API Keys](#api-keys) for details.

5. **Run the Project:**
Execute the main script ```ConceptGenerator.py ```. Refer Section [Data Generation and Post-Processing](#data-generation-and-post-processing) for details.

6. **Explore the Output:**
Check the project's output at Google Firestore or local files saved in the data-folder.

## Technologies Used
Concept Generator is written in Python and utilizes Firestore, a cloud-based NoSQL database service, for data management.
## Folder Structure
The project directory is organized as follows:

* ConceptGenerator.py: The entry point
* src/: Contains functions for data processing
* utils/: Holds utility functions for credentials etc
* data/: Stores local data files


## Data Generation and Post-Processing
All data generation and post-processing are done in ```ConceptGenerator.py ```.
The script is meant to be run one step at the time, and all the steps will 
be explained in the next subchapters.

### Generate Interconnected Concepts with ChatGPT 
To run this step, set ```mode='generate_connections'``` in ```ConceptGenerator.py ```. 
Also, specify a starting concept (e.g., ```starting_concept='mind'```) 
and the end recursion depth (e.g., ```end_depth = 3```). 
The start depth should always be set to 0 (i.e., ```start_depth = 0```).

The iteration begins with the starting concept (Level 0), which is 
first input into ChatGPT to generate 8 related concepts (Level 1). 
Each of these related concepts is then fed into ChatGPT to generate 
even more related concepts (Level 2). The iteration continues until 
the desired recursion depth is reached (e.g., ```end_depth = 3```).

In theory, the algorithm yields 8 times more concepts for each iteration. 
In practice, however, concepts start reappearing, and since the algorithm 
does not need to recompute them, the overall computational complexity 
increases less. The actual increase per depth level depends, for example, 
on the internal consistency of the starting concept.

The script outputs a dictionary that contains the starting concept and 
all iterated concepts. One key-value pair looks like this:

```"perception": {"branch": [["truth", 2]], "concepts": ["sensation", "awareness", "interpretation", "cognition", "attention", "stimulus", "consciousness", "recognition"]}```

The first item in 'branch' array is the starting concept that yielded
this concept. The second item is the recursion depth at which 
this concept appeared (e.g., 1 = direct child of the starting concept).
The 'concepts' is an 8-item array where each item is one related 
concept (direct child of the concept).

We ran the script for the following starting concepts: 
artificial intelligence, energy, hierarchy, identity, 
innovation, interdependence, justice, leadership, mind, problem solving, truth

Each run resulted in a dictionary that was saved locally as:
`data/raw_concept_data_[STARTING CONCEPT].txt`

where `STARTING CONCEPT` is the name of the starting concept.

### Refine Concept Connections
This step utilizes the raw data generated in the previous step. To run this step, 
set ```mode='combine_data_and_refine'``` in ```ConceptGenerator.py ```. 
#### Combine Raw Data

The previously generated dictionaries where located with `data/raw_concept_data_`
identifier in the folder structure and combined. 

We removed multiple entries since the same concept can appear from multiple starting 
concepts. However, we kept track of their appearance in the 'branch' array 
(e.g., `"branch": [["identity", 3], ["justice", 3]]` would mean that this concept
appears from both 'identity' and 'justice' at Level 3)

#### Get Backward Connections
The data so far has a main weakness in that concept connections are unilateral. 
That is, Concept A yields 8 related concepts, but Concept A can also appear as 
a related concept for other input concepts. 
The `iterate_backward_connections` function 
sorts out these connections, resulting in an additional key, 
`backward_concepts`, with an array containing these connections as values.

#### Sort Concepts By Popularity
The refined data so far contains an 8-item array of forward connections 
and a variable-length array of backward connections, the latter depending 
on the popularity of the concept. In most use cases, however, there is 
a desire to provide a fixed-length array of connections, either forward 
or backward, sorted by popularity.

The `compute_concept_popularity` function counts whether or not the 
concept appears as a key and how many times it appears as a related 
concept for other concepts. In the present function, the former has a 
factor of 100, and the latter has a factor of 1, ensuring that 
concepts that are keys always have priority.

The `sort_concept_by_popularity` function, in turn, creates a key, 
`ordered_concepts`, with an array containing the eight most popular 
concepts in descending order, scored in the previous step.

Finally, `concepts` and `backward_concepts` are deleted from this 
dictionary, leaving only `ordered_concepts` as concept data.

This dictionary is stored locally as `combined_refined_concept_data.txt`.

### Evaluate Concepts with ChatGPT

This step involves the evaluation of the concepts created earlier. 
To execute this step, set ```mode='create_evaluation_ratings'``` 
in ```ConceptGenerator.py ```.

The concepts can be evaluated across any user-defined dimension. To define a dimension,
use the following format (e.g., ```dimension = ['concrete', 'abstract']```). The upper
end of the dimension is also used as the name for the output files 
(e.g., produces a subkey `abstract`). Here, we have used "concrete vs. abstract" 
as an example dimension. 

It's worth mentioning the suitability of ChatGPT 3.5 for such an evaluation. 
One way to obtain the desired data would be to request ChatGPT to return a 
score ranging from 0 (=concrete) to 1 (=abstract). However, this approach 
yielded unreliable and counter-intuitive results. A more robust approach 
implemented here is to request ChatGPT to sort the input concepts from 
the most concrete to the most abstract. The exact reason why the latter 
approach is better is unclear, but it probably has to do with the fact 
that Large Language Models (LLMs), unlike general-purpose computers, 
excel in processing verbal rather than numerical information.


The method used here begins with initializing a dictionary where all concepts 
serve as keys, with empty arrays as their corresponding values.

The repeated steps are as follows:

- Measure the length of the value array for each concept
- Select 110 keys with the shortest value arrays (randomize for equal values)
- In chunks of 11, request ChatGPT to sort the concepts
- Based on the location in the sorted array, assign a value between 0 and 1 to each concept
- Return all 110 values and append them to the original dictionary
- Save the value array in case one ChatGPT request crashes at some point
- Repeat the above steps until the defined minimum length of the value array has been reached


With the same number of ChatGPT requests compared to the naive approach 
discussed earlier, this method allows each concept to be rated 11 times. 
This reduces the impact of random erroneous results, which ChatGPT sometimes produces.

The `generate_concept_rating` function is responsible for taking 110 concepts 
(or any number divisible by 11) and returning a value dictionary. 
These values are then appended to the final data stored in `dimension_rating_data.txt`.

It is important to note that the boolean variable 
`append_existing_rating_data` determines whether the final data 
file is appended or overwritten. For the initial run, this should 
be set to `False`, and then switched to `True`. The value should be `True`
also when another dimension (e.g., simple vs. complex) is being added.

### Add Ratings to Interconnectedness Data

This step combines the rating data `dimension_rating_data.txt` 
and the interconnectedness data `combined_refined_concept_data.txt` into a single file.
To run this step, set ```mode='combine_final_file'``` in ```ConceptGenerator.py ```.

Additionally, you can use `ratings_to_be_included` to control which ratings are added 
(e.g.,```ratings_to_be_included=['abstract', 'complex']```). Please ensure that `dimension_rating_data.txt` contains rating data for any 
dimension specified here. The user can also set ratings_to_be_included to ['all'] or [].

The resulting dictionary is stored locally as `final_connection_data.txt`.

### Write to Firestore

The previously generated data is the final data for local inspection, 
but we also store it in Google Firestore for global use. 
To run this step, set ```mode='write_to_firestore'``` in ```ConceptGenerator.py ```.

To make the data Firestore compliant, we first need to flatten the nested 
structure in the 'branch' data (e.g., `[["identity", 3], ["justice", 3]]` 
becomes `["identity", 3 ,"justice", 3]`).

Since Firestore documents have size limitations, we also split the dictionary 
into multiple documents if necessary (i.e., `chunk_size = 200000`).

The data is stored in Firestore as follows:

 - **`conceptBrowser`** (Collection)
    - **`finalConceptData_0`** (Document)
    - **`finalConceptData_1`** (Document)
    - etc
        - **`abstract`** (Number): Rating from 0 (concrete) to 100 (abstract)
        - **`branch`** (Array): The starting concept, its level, ...
        - **`ordered_concepts`** (Array of Strings): An array of the 8 most related concepts to this concept, ordered by relatedness

### Summarize Concepts with ChatGPT

This step involves requesting ChatGPT to generate an 80-word summary for each concept. 
To run this step, set ```mode='define'``` in ```ConceptGenerator.py ```.

The script iterates through all the concepts that serve as keys 
in the interconnectedness data dictionary. For each concept, the script 
first checks Firestore to determine whether a summary already exists. 
If a summary is found, the concept is skipped.

The `generate_concept_definition` function sends a request to 
ChatGPT to create a summary. It returns a dictionary with keys `definition,` `model,`
and `date`. The value of the first key contains the actual summary, 
the second key contains the text "ChatGPT 3.5," and the third key contains 
the retrieval date.

The data is stored in Firestore as follows:

 - **`conceptNames`** (Collection)
    - **`[CONCEPT NAME]`** (Document)
        - **`definition`** (String): A concise summary (about 70 words) about the concept
        - **`date`** (Timestamp): The date and time when ChatGPT generated the definition
        - **`definition_model_version`** (String): The version of ChatGPT used to generate the definition

Where `CONCEPT NAME` is the name of each concept.

### Data Collection Management

A few words about overall data management are worth noting. First, 
it is important to realize that ChatGPT requests are quite time-consuming, 
error-prone, and they cost real money. Therefore, the focus here is on 
saving data frequently and ensuring that scripts can resume their actions 
wherever ChatGPT encounters an issue, for example.

Here's how we accomplish this in different scripts:

- For initial data collection, the iterator returns the data after 
`run_for_sec_before_save = 10` and then resumes the action
- In the evaluation script, 110 ratings are requested at a time and appended to the data file before requesting new ratings.
- The summary generation script interacts with Firestore directly and checks which summaries have already been written.

## API Keys
### ChatGPT

Access to the ChatGPT API requires an OpenAI account. Here, the API key 
is saved as an environmental variable `OPENAI_API_KEY` and retrieved 
by the `my_openai()` function located in `utils/my_openai_creds.py`.

### Firestore

We use Firestore to store the final data. However, all intermediate results 
are saved locally, so the use of Firestore is optional.

To use Firestore, you need a Google account and initialization 
in the Google Cloud Platform. Here, the `init_firebase()` function 
reads a locally stored credentials certificate.

## Known Issues
- The quality of evaluation ratings is still mediocre
## Roadmap
- Explore new ways to use ChatGPT for evaluations
- Develop an automated and error-tolerant framework for running complex ChatGPT requests

## Contact Information
