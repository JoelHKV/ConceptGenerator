# Concept Generator

## General Information
Concept Generator utilizes ChatGPT 3.5 to generate multifaceted data 
about concepts, which are fundamental building blocks in thinking. 
The project yields:

- a mesh of interconnected concepts
- evaluation of concepts across any dimension
- summary of concepts

The outcome of the project is a Google Firestore database that provides 
easy and efficient access to the generated data. In fact, 
[ConceptExplorer](https://github.com/JoelHKV/ConceptExplorer) is a web app 
that utilizes the data generated in this project in a user-friendly manner.

## Introduction

Concepts are the foundation of human thinking and understanding. 
They allow us to make sense of the world by organizing information 
into meaningful categories. While we grasp many concepts, 
our understanding of them is often intuitive rather than explicit. 
For example, explaining what 'the mind' truly is or identifying 
closely related concepts can be challenging.

The Concept Generator project takes a systematic approach to the 
world of concepts by harnessing the power of ChatGPT 3.5. 
With Concept Generator, you can:

- Initiate the creation of a concept network from user-defined starting points
- Delve deep into the relationships between concepts, identifying the most closely related ideas
- Explore the abstractness of these ideas, providing valuable insights into the spectrum of thought
- Access clear and concise summaries for each concept, making complex ideas more accessible
 
The project produces data that can be used to:

- Learn new concepts
- Enhance the understanding of concepts already known
- Acquire knowledge about the interconnections between concepts
- Categorize and rate concepts across various dimensions

In essence, the data generated by this project can improve one's conceptual thinking skills, better equipping individuals to interact with the world around them.

The project is designed for learners, educators, researchers, and anyone curious about the intricacies of human thought.

Additionally, explore [ConceptExplorer](https://github.com/JoelHKV/ConceptExplorer), the application-side sister project that complements this endeavor.
 

## Getting Started
To run this project locally, follow these 5 steps:

1. **Installation:**
Ensure you have Python 3.9.5 or a more recent version installed on your system.

2. **Clone the Repository:**
```
git clone https://github.com/JoelHKV/ConceptGenerator.git
```
3. **Install Dependencies:**
Navigate to the project directory and install dependencies:
```
pip install -r requirements.txt
```
4. **Configuration:**
Set up API keys. Refer Section [API Keys](#api-keys) for details.

5. **Run the Project:**
Execute the main script ```ConceptGenerator.py ```. Refer Section [Data Generation and Post-Processing](#data-generation-and-post-processing) for details.


6. **Explore the Output:**
Check the project's output at Google Firestore or local files saved in the data-folder.

 
## Technologies Used
Concept Generator is written in Python and utilizes Firestore, a cloud-based NoSQL database service, for data management.
## Folder Structure
The project directory is organized as follows:

* ConceptGenerator.py: The entry point for all steps in the way.
* src/: Contains functions for data processing.
* utils/: Holds utility functions for credentials etc.
* data/: Stores example data (not a functional part as actual data is handled by Firestore).



## Data Generation and Post-Processing
Data generation is done one step at a time. Furthermore, the approach 
is designed so that hour-long ChatGPT request queues can be stopped 
and resumed without the need to restart from the beginning. 
Additionally, more levels of concept recursion can be added without 
having to rerun lower levels first.

### Generate Interconnected Concepts with ChatGPT 
To run this step, set ```mode='generate_connections'``` in ```ConceptGenerator.py ```. 
Also, specify a starting concept (e.g., ```concept_end_point='mind'```) 
and the starting and ending recursion depths (e.g., ```start_depth = 0```, ```end_depth = 3```).

The iteration begins with the starting concept (Level 0), which is 
first inputted to ChatGPT to generate 8 related concepts (Level 1). Each of these
related concepts is then inputted to ChatGPT to generate even more related concepts (Level 2).
The iteration continues until the desired recursion depth is reached  (e.g., ```end_depth = 3```).

In theory, the algoritm yields 8 times more concepts for each iteration. In practice, 
concepts start re-appearing and since the algoritm does not recompute them, 
the overall complexity is less. 


The script outputs a dictionary where each iterated concept is a key. 
One line looks like this:

```"perception": {"branch": [["truth", 2]], "concepts": ["sensation", "awareness", "interpretation", "cognition", "attention", "stimulus", "consciousness", "recognition"]}```

Within each key, there is a 'branch' key with a 2-item array as a value. The first one
is the starting concept and the second one is the recursion depths. 
The second key, 'concepts,' contains 
an 8-item array, with each item representing one related 
concept created by ChatGPT.

The resulted dictionary is saved locally as `data/raw_concept_data_truth.txt`.

Here, 10 interations where fun 



### Refine Concept Connections
This step utilizes the raw data generated in the previous step. To run this step, 
set ```mode='refine'``` in ```ConceptGenerator.py ```. 
#### Get Backward Connections
The raw data generated in the previous step has a main weakness in that 
concept connections are unilateral. That is, Concept A yields 8 
related concepts, but Concept A can also appear as a related concept 
for other inputted concepts. The `iterate_backward_connections` function 
sorts out these connections, resulting in an additional key, 
`backward_concepts`, with an array containing these connections as values.

#### Sort Concepts By Popularity
The data collected so far contains an 8-item array of forward connections 
and a variable-length array of backward connections, the latter depending 
on the popularity of the concept. In most use cases, however, there is 
a desire to provide a fixed-length array of connections, either forward 
or backward, sorted by popularity.

The `compute_concept_popularity` function counts whether or not the 
concept appears as a key and how many times it appears as a related 
concept for other concepts. In the present function, the former has a 
factor of 100, and the latter has a factor of 1, ensuring that 
concepts that are keys always have priority.

The `sort_concept_by_popularity` function, in turn, creates a key, 
`ordered_concepts`, with an array containing the eight most popular 
concepts in descending order, scored in the previous step.

Finally, `concepts` and `backward_concepts` are deleted from this 
dictionary, leaving only `ordered_concepts` as concept data.

This performant dictionary is the final interconnectedness data 
stored in Firestore as: 

- **`conceptBrowser`** (Collection)
  - **`concepts_refined`** (Collection)

It is also saved locally as `data/refined_data.txt`.

### Evaluate Concepts with ChatGPT

This step evaluates the concepts (=keys in the previously 
created dictionary) across a user-defined dimension. 
To run this step, set ```mode='rate'``` in ```ConceptGenerator.py ```.
Furthermore, to evaluate concepts in the concreteness versus abstractness dimension, 
set ```dimension = ['concrete', 'abstract']```.

A few words about the suitability of ChatGPT 3.5 for such an evaluation 
are worth noting. One way to obtain the desired data would be to 
request ChatGPT to return a score from 0 (=concrete) to 1 (=abstract). 
However, this approach yielded unreliable and counter-intuitive results. 
A more robust approach implemented here is to request ChatGPT to sort 
the inputted concepts from most concrete to most abstract. 
The exact reason why the latter approach is better is unclear, 
but it probably has to do with the fact that Large Language Models (LLM), 
contrary to computers in general, are better suited for verbal rather 
than numerical information.

The method used here includes the following steps:

- Randomly split the original concepts into groups of 10 (or 9)
- Request ChatGPT to sort them 
- Run the sorting script for all subsets
- Repeat the above steps 10 times
- Compute the rating for each concept based on its average position across all 10 occurences 

The total number of ChatGPT requests is almost identical to 
the naive approach discussed earlier. However, the data quality, 
thanks to the nature of LLM, is much better. 
The fact that each rating is an average of 10 sortings also reduces 
the impact of random erroneous results, which ChatGPT sometimes produces.

The `generate_concept_rating` function completes the task and the ratings are stored in Firestore as:  

- **`conceptBrowser`** (Collection)
  - **`abstract_ratings`** (Collection)

They are also saved locally as `data/abst_rating_data.txt`. 

### Add Ratings to Interconnectedness Data

This step adds the previous rating data to the interconnectedness dictionary.
Solely for performance optimization purposes, this data is placed where 
other relevant data is already located. 
To run this step, set ```mode='add_rate'``` in ```ConceptGenerator.py ```.

The script adds a key `abstract` to `concepts_refined` with a value that is the previously generated abstractness rating.


### Summarize Concepts with ChatGPT

This step requests ChatGPT to generate an 80-word summary of each concept. 
To run this step, set ```mode='define'``` in ```ConceptGenerator.py ```. 

The `generate_concept_definition` function sends a request to ChatGPT to 
generate a summary. It returns a dictionary with keys `definition,` `model,`
and `date`. The value for the first one is the actual summary, 
for the second text `ChatGPT 3.5`, and for the third the retrieval date.

Each data entry is saved in Firestore as:
 
 - **`conceptNames`** (Collection)
  - **`[CONCEPT NAME]`** (Collection)

Finally, the script loops through all the concepts that are keys in the 
interconnectedness data dictionary. 

## Database Schema
### All Interconnections
Data related to interconnections between concepts is stored in Firestore under the following structure:

- **`conceptBrowser`** (Collection)
  - **`concepts_refined`** (Collection)
    - **`[Concept Name]`** (Document)
      - **`abstract`** (Number): Abstractness rating from 0 (concrete) to 100 (abstract).
      - **`branch`** (String): The starting concept that led to this concept.
      - **`ordered_concepts`** (Array of Strings): An array of the 8 most related concepts to this concept, ordered by relatedness.

### Concept Details
Details about individual concepts are stored in Firestore using the following structure:

- **`conceptNames`** (Collection)
  - **`[Concept Name]`** (Document)
    - **`definition`** (String): A concise summary (about 70 words) about the concept.
    - **`date`** (Timestamp): The date and time when ChatGPT generated the definition.
    - **`definition_model_version`** (String): The version of ChatGPT used to generate the definition.

This structure helps organize and retrieve data efficiently, allowing for easy access to interconnections between concepts and detailed information about each concept.

## API Keys
### ChatGPT
Access to ChatGPT API requires an OpenAI account. Here, API key is saved as an environmental variable OPENAI_API_KEY and retrieved by `my_openai()` function located in `utils/my_openai_creds.py`

### Google Cloud Platform & Firestore

We utilize Google Firestore to store both intermediate and final data. 
This necessitates having a Google account and initializing Firestore 
in the Google Cloud Platform. 
The `init_firebase()` function reads a locally stored credentials certificate.

However, it's important to note that the use of Firestore 
is not necessary, as both intermediate and final data 
can also be saved locally. In fact, most functions save 
files locally for inspection.
 
## Licence
## Known Issues
## Roadmap
- Find even better ways to evaluate concepts with ChatGPT
## Contact Information
